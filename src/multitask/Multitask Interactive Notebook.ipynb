{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reuben/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/reuben/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "/home/reuben/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/reuben/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "import config as cf\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.65)\n",
    "session = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "keras.backend.tensorflow_backend.set_session(session)\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "import itertools\n",
    "\n",
    "import random\n",
    "\n",
    "bs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label-Asymmetry Score\n",
    "df_1 = pd.read_excel(cf.DATA_CONFIG['data_folder'] + 'group/group01.xlsx')\n",
    "df_2 = pd.read_excel(cf.DATA_CONFIG['data_folder'] + 'group/group02.xlsx')\n",
    "df_3 = pd.read_excel(cf.DATA_CONFIG['data_folder'] + 'group/group03.xlsx')\n",
    "df_4 = pd.read_excel(cf.DATA_CONFIG['data_folder'] + 'group/group04.xlsx')\n",
    "df_5 = pd.read_excel(cf.DATA_CONFIG['data_folder'] + 'group/group05.xlsx')\n",
    "df_6 = pd.read_excel(cf.DATA_CONFIG['data_folder'] + 'group/group06.xlsx')\n",
    "df_7 = pd.read_excel(cf.DATA_CONFIG['data_folder'] + 'group/group07.xlsx')\n",
    "df_3 = df_3.reset_index()\n",
    "df_7 = df_7.dropna()\n",
    "df_7 = df_7.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reuben/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Reading each excel file containing crowd sourced attributes\n",
    "a_1 = (preprocessing.scale(df_1['Asymmetry_1_1']) + preprocessing.scale(df_1['Asymmetry_1_2']) + preprocessing.scale(\n",
    "    df_1['Asymmetry_1_3'])) / 3.0\n",
    "a_2 = (preprocessing.scale(df_2['Asymmetrie']) + preprocessing.scale(df_2['Unnamed: 3']) + preprocessing.scale(\n",
    "    df_2['Unnamed: 4'])) / 3.0\n",
    "a_3 = (preprocessing.scale(df_3['Asymmetry_3_1']) + preprocessing.scale(df_3['Asymmetry_3_2']) + preprocessing.scale(\n",
    "    df_3['Asymmetry_3_3'])) / 3.0\n",
    "a_4 = (preprocessing.scale(df_4['Asymmetry_4_1']) + preprocessing.scale(df_4['Asymmetry_4_3']) + preprocessing.scale(\n",
    "    df_4['Asymmetry_4_5'])) / 3.0\n",
    "a_5 = (preprocessing.scale(df_5['Asymmetry_5_1']) + preprocessing.scale(df_5['Asymmetry_5_2']) + preprocessing.scale(\n",
    "    df_5['Asymmetry_5_3'])) / 3.0\n",
    "a_6 = (preprocessing.scale(df_6['Asymmetry_6_1']) + preprocessing.scale(df_6['Asymmetry_6_2']) + preprocessing.scale(\n",
    "    df_6['Asymmetry_6_3'])) / 3.0\n",
    "a_7 = (preprocessing.scale(df_7['Asymmetry_7_1']) + preprocessing.scale(\n",
    "    df_7['Asymmetry_7_2']) + preprocessing.scale(df_7['Asymmetry_7_3']) + preprocessing.scale(\n",
    "    df_7['Asymmetry_7_4']) + preprocessing.scale(df_7['Asymmetry_7_5']) + preprocessing.scale(\n",
    "    df_7['Asymmetry_7_6'])) / 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Image filename list and label for asymmetry\n",
    "asymm_label = np.concatenate((a_1, a_2, a_3, a_4, a_5, a_6, a_7))\n",
    "asymm_id = np.concatenate(\n",
    "    (df_1['ID'], df_2['Afbeelding'], df_3['index'], df_4['ID'], df_5['ID'], df_6['ID'], df_7['ID']))\n",
    "# Image filename list and label for asymmetry\n",
    "asymm_label = np.concatenate((a_1, a_2, a_3, a_4, a_5, a_6, a_7))\n",
    "asymm_id = np.concatenate(\n",
    "    (df_1['ID'], df_2['Afbeelding'], df_3['index'], df_4['ID'], df_5['ID'], df_6['ID'], df_7['ID']))\n",
    "\n",
    "# Image filename list and label for class\n",
    "df = pd.read_csv(cf.DATA_CONFIG['data_folder'] + 'csv/ISIC-2017_Training_Part3_GroundTruth.csv')\n",
    "class_label = df['melanoma']\n",
    "class_id = df['image_id']\n",
    "\n",
    "a_label = []\n",
    "mask = []\n",
    "for i in range(len(class_id)):\n",
    "    for j in range(len(asymm_id)):\n",
    "        if (class_id[i] == asymm_id[j]):\n",
    "            a_label.append(asymm_label[j])\n",
    "            mask.append(1.)\n",
    "            break\n",
    "        elif (j == 689):  # length of asymmetry_id array\n",
    "            a_label.append(0.)\n",
    "            mask.append(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id_ = []\n",
    "class_label_ = []\n",
    "a_label_ = []\n",
    "mask_ = []\n",
    "\n",
    "# Shuffle dataset\n",
    "indexes = list(range(len(class_id)))\n",
    "random.Random(4).shuffle(\n",
    "    indexes)  # To produce same train and valid set every time. DO NOT use seed=4, because it will pollute randomness of the rest of the program.\n",
    "for index in indexes:\n",
    "    class_id_.append(class_id[index])\n",
    "    class_label_.append(class_label[index])\n",
    "    a_label_.append(a_label[index])\n",
    "    mask_.append(mask[index])\n",
    "\n",
    "train_id = class_id_[:-600]  # 1400 training\n",
    "train_label_c = class_label_[:-600]\n",
    "train_label_a = a_label_[:-600]\n",
    "train_mask = mask_[:-600]\n",
    "\n",
    "valid_id = class_id_[1400:1750]  # 350 valid\n",
    "valid_label_c = class_label_[1400:1750]\n",
    "valid_label_a = a_label_[1400:1750]\n",
    "valid_mask = mask_[:-600]\n",
    "\n",
    "test_id = class_id_[1750:]  # 250 test\n",
    "test_label_c = class_label_[1750:]\n",
    "test_label_a = a_label_[1750:]\n",
    "test_mask = mask_[:-600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generator\n",
    "def generate_data(directory, augmentation, shuffle, batch_size, file_list, label_1, label_2, mask):\n",
    "    i = 0\n",
    "    shuff_file_list = file_list\n",
    "    shuff_label_1 = label_1\n",
    "    shuff_label_2 = label_2\n",
    "    shuff_mask = mask\n",
    "\n",
    "    while True:\n",
    "        image_batch = []\n",
    "        label_1_batch = []\n",
    "        label_2_batch = []\n",
    "        sample_weight = []\n",
    "        for b in range(batch_size):\n",
    "            if i == (len(file_list)):\n",
    "                i = 0\n",
    "                if shuffle == True:\n",
    "                    new_file_list = []\n",
    "                    new_label_1 = []\n",
    "                    new_label_2 = []\n",
    "                    new_mask = []\n",
    "                    indexes = list(range(len(shuff_file_list)))\n",
    "                    random.shuffle(indexes)\n",
    "                    for index in indexes:\n",
    "                        new_file_list.append(shuff_file_list[index])\n",
    "                        new_label_1.append(shuff_label_1[index])\n",
    "                        new_label_2.append(shuff_label_2[index])\n",
    "                        new_mask.append(shuff_mask[index])\n",
    "                    shuff_file_list = new_file_list\n",
    "                    shuff_label_1 = new_label_1\n",
    "                    shuff_label_2 = new_label_2\n",
    "                    shuff_mask = new_mask\n",
    "\n",
    "            img = image.load_img(directory + shuff_file_list[i] + '.jpg', grayscale=False, target_size=(384, 384))\n",
    "            img = image.img_to_array(img)\n",
    "            if augmentation == True:\n",
    "                datagen = ImageDataGenerator(\n",
    "                    rotation_range=360,\n",
    "                    width_shift_range=0.1,\n",
    "                    height_shift_range=0.1,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    channel_shift_range=20,\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip=True,\n",
    "                    fill_mode=\"nearest\")\n",
    "                img = datagen.random_transform(img)\n",
    "                img = img / 255.0\n",
    "\n",
    "            if augmentation == False:\n",
    "                img = img / 255.0\n",
    "            image_batch.append(img)\n",
    "            label_1_batch.append(shuff_label_1[i])\n",
    "            label_2_batch.append(shuff_label_2[i])\n",
    "            sample_weight.append(shuff_mask[i])\n",
    "            i = i + 1\n",
    "\n",
    "        if (all(sample == 0 for sample in sample_weight)):\n",
    "            yield (np.asarray(image_batch_r),\n",
    "                   ({'out_class': np.asarray(label_1_batch_r), 'out_asymm': np.asarray(label_2_batch_r)}),\n",
    "                   ({'out_asymm': np.asarray(sample_weight_r)}))\n",
    "        else:\n",
    "            image_batch_r = image_batch  # Memory, when all the samples for asymmetry score is zero generator returns previous batch instead of zeros\n",
    "            label_1_batch_r = label_1_batch\n",
    "            label_2_batch_r = label_2_batch\n",
    "            sample_weight_r = sample_weight\n",
    "            yield (\n",
    "            np.asarray(image_batch), ({'out_class': np.asarray(label_1_batch), 'out_asymm': np.asarray(label_2_batch)}),\n",
    "            ({'out_asymm': np.asarray(sample_weight)}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "train=generate_data(directory=cf.DATA_CONFIG['data_folder'] + 'image_data/', augmentation=True, shuffle=True, batch_size=bs, file_list=train_id, label_1=train_label_c, label_2=train_label_a, mask=train_mask)\n",
    "\n",
    "validation=generate_data(directory=cf.DATA_CONFIG['data_folder'] + 'image_data/', augmentation=False, shuffle=True, batch_size=bs, file_list=valid_id, label_1=valid_label_c, label_2=valid_label_a, mask=valid_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 384, 384, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 384, 384, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 384, 384, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 192, 192, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 192, 192, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 192, 192, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 96, 96, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 96, 96, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 96, 96, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 96, 96, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 48, 48, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 48, 48, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 48, 48, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 48, 48, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 24, 24, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 24, 24, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 24, 24, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 24, 24, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 12, 12, 512)  0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 512)          0           block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          51300       global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          10100       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_class (Dense)               (None, 1)            101         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_asymm (Dense)               (None, 1)            101         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,776,290\n",
      "Trainable params: 14,776,290\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build the model\n",
    "img_height, img_width, img_channel=384,384,3\n",
    "input_tensor = Input(shape=(img_height, img_width, img_channel))\n",
    "vgg_new_model = keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor, input_shape=(img_height, img_width, img_channel), pooling='avg')\n",
    "for layer in vgg_new_model.layers[:-5]:\n",
    "    layer.trainable = True\n",
    "l2=Dense(100, activation='relu')(vgg_new_model.output)\n",
    "l3=Dense(100, activation='relu')(l2)\n",
    "out_class=Dense(1, activation='sigmoid', name='out_class')(l3)\n",
    "out_asymm=Dense(1, activation='linear', name='out_asymm')(l3)\n",
    "model= Model(inputs=vgg_new_model.input, outputs=[out_class, out_asymm])\n",
    "\n",
    "#Check the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reuben/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "140/140 [==============================] - 93s 667ms/step - loss: 0.8977 - out_class_loss: 1.2015 - out_asymm_loss: 0.5940 - out_class_acc: 0.2771 - val_loss: 0.4931 - val_out_class_loss: 0.6978 - val_out_asymm_loss: 0.2885 - val_out_class_acc: 0.1914\n",
      "Epoch 2/200\n",
      "140/140 [==============================] - 91s 652ms/step - loss: 0.9037 - out_class_loss: 1.2123 - out_asymm_loss: 0.5951 - out_class_acc: 0.1879 - val_loss: 0.4617 - val_out_class_loss: 0.7135 - val_out_asymm_loss: 0.2099 - val_out_class_acc: 0.1971\n",
      "Epoch 3/200\n",
      "140/140 [==============================] - 91s 650ms/step - loss: 0.9240 - out_class_loss: 1.2037 - out_asymm_loss: 0.6442 - out_class_acc: 0.1850 - val_loss: 0.4730 - val_out_class_loss: 0.7214 - val_out_asymm_loss: 0.2246 - val_out_class_acc: 0.1914\n",
      "Epoch 4/200\n",
      "140/140 [==============================] - 91s 649ms/step - loss: 0.8987 - out_class_loss: 1.1962 - out_asymm_loss: 0.6012 - out_class_acc: 0.1821 - val_loss: 0.4840 - val_out_class_loss: 0.7224 - val_out_asymm_loss: 0.2456 - val_out_class_acc: 0.1886\n",
      "Epoch 5/200\n",
      "140/140 [==============================] - 91s 649ms/step - loss: 0.9034 - out_class_loss: 1.2014 - out_asymm_loss: 0.6055 - out_class_acc: 0.1843 - val_loss: 0.5056 - val_out_class_loss: 0.7264 - val_out_asymm_loss: 0.2849 - val_out_class_acc: 0.1971\n",
      "Epoch 6/200\n",
      "140/140 [==============================] - 91s 649ms/step - loss: 0.9085 - out_class_loss: 1.2103 - out_asymm_loss: 0.6067 - out_class_acc: 0.1879 - val_loss: 0.4821 - val_out_class_loss: 0.7311 - val_out_asymm_loss: 0.2331 - val_out_class_acc: 0.1971\n",
      "Epoch 7/200\n",
      "140/140 [==============================] - 91s 649ms/step - loss: 0.9183 - out_class_loss: 1.2029 - out_asymm_loss: 0.6336 - out_class_acc: 0.1850 - val_loss: 0.5202 - val_out_class_loss: 0.7323 - val_out_asymm_loss: 0.3082 - val_out_class_acc: 0.1914\n",
      "Epoch 8/200\n",
      "140/140 [==============================] - 91s 648ms/step - loss: 0.9349 - out_class_loss: 1.2083 - out_asymm_loss: 0.6616 - out_class_acc: 0.1871 - val_loss: 0.4917 - val_out_class_loss: 0.7323 - val_out_asymm_loss: 0.2511 - val_out_class_acc: 0.1914\n",
      "Epoch 9/200\n",
      "140/140 [==============================] - 91s 648ms/step - loss: 0.9050 - out_class_loss: 1.2029 - out_asymm_loss: 0.6071 - out_class_acc: 0.1850 - val_loss: 0.5034 - val_out_class_loss: 0.7366 - val_out_asymm_loss: 0.2702 - val_out_class_acc: 0.1857\n",
      "Epoch 10/200\n",
      "140/140 [==============================] - 91s 648ms/step - loss: 0.9059 - out_class_loss: 1.2081 - out_asymm_loss: 0.6037 - out_class_acc: 0.1871 - val_loss: 0.5125 - val_out_class_loss: 0.7370 - val_out_asymm_loss: 0.2880 - val_out_class_acc: 0.1914\n",
      "Epoch 11/200\n",
      "140/140 [==============================] - 91s 649ms/step - loss: 0.9027 - out_class_loss: 1.2012 - out_asymm_loss: 0.6041 - out_class_acc: 0.1843 - val_loss: 0.5060 - val_out_class_loss: 0.7365 - val_out_asymm_loss: 0.2756 - val_out_class_acc: 0.1914\n",
      "Epoch 12/200\n",
      "140/140 [==============================] - 91s 649ms/step - loss: 0.9144 - out_class_loss: 1.1962 - out_asymm_loss: 0.6326 - out_class_acc: 0.1821 - val_loss: 0.5011 - val_out_class_loss: 0.7338 - val_out_asymm_loss: 0.2685 - val_out_class_acc: 0.1914\n",
      "Epoch 13/200\n",
      "140/140 [==============================] - 91s 649ms/step - loss: 0.9012 - out_class_loss: 1.2047 - out_asymm_loss: 0.5978 - out_class_acc: 0.1857 - val_loss: 0.4974 - val_out_class_loss: 0.7355 - val_out_asymm_loss: 0.2594 - val_out_class_acc: 0.1914\n",
      "Epoch 14/200\n",
      "140/140 [==============================] - 91s 649ms/step - loss: 0.8967 - out_class_loss: 1.2064 - out_asymm_loss: 0.5870 - out_class_acc: 0.1864 - val_loss: 0.4915 - val_out_class_loss: 0.7355 - val_out_asymm_loss: 0.2476 - val_out_class_acc: 0.1914\n",
      "Epoch 15/200\n",
      "140/140 [==============================] - 91s 648ms/step - loss: 0.9187 - out_class_loss: 1.2098 - out_asymm_loss: 0.6275 - out_class_acc: 0.1879 - val_loss: 0.5041 - val_out_class_loss: 0.7343 - val_out_asymm_loss: 0.2739 - val_out_class_acc: 0.1886\n",
      "Epoch 16/200\n",
      "140/140 [==============================] - 91s 649ms/step - loss: 0.9173 - out_class_loss: 1.2047 - out_asymm_loss: 0.6299 - out_class_acc: 0.1857 - val_loss: 0.5086 - val_out_class_loss: 0.7361 - val_out_asymm_loss: 0.2812 - val_out_class_acc: 0.1857\n",
      "Epoch 17/200\n",
      "140/140 [==============================] - 91s 649ms/step - loss: 0.8970 - out_class_loss: 1.2029 - out_asymm_loss: 0.5911 - out_class_acc: 0.1850 - val_loss: 0.5012 - val_out_class_loss: 0.7375 - val_out_asymm_loss: 0.2648 - val_out_class_acc: 0.1943\n",
      "Epoch 18/200\n",
      "140/140 [==============================] - 91s 649ms/step - loss: 0.9071 - out_class_loss: 1.2065 - out_asymm_loss: 0.6076 - out_class_acc: 0.1864 - val_loss: 0.4874 - val_out_class_loss: 0.7385 - val_out_asymm_loss: 0.2364 - val_out_class_acc: 0.1886\n",
      "Epoch 19/200\n",
      "140/140 [==============================] - 91s 649ms/step - loss: 0.9177 - out_class_loss: 1.2046 - out_asymm_loss: 0.6307 - out_class_acc: 0.1857 - val_loss: 0.5346 - val_out_class_loss: 0.7347 - val_out_asymm_loss: 0.3346 - val_out_class_acc: 0.1943\n",
      "Epoch 20/200\n",
      "140/140 [==============================] - 91s 649ms/step - loss: 0.9195 - out_class_loss: 1.1961 - out_asymm_loss: 0.6428 - out_class_acc: 0.1821 - val_loss: 0.5191 - val_out_class_loss: 0.7356 - val_out_asymm_loss: 0.3027 - val_out_class_acc: 0.1886\n",
      "Epoch 21/200\n",
      "140/140 [==============================] - 91s 649ms/step - loss: 0.8999 - out_class_loss: 1.2098 - out_asymm_loss: 0.5901 - out_class_acc: 0.1879 - val_loss: 0.4693 - val_out_class_loss: 0.7314 - val_out_asymm_loss: 0.2071 - val_out_class_acc: 0.1886\n",
      "Epoch 22/200\n",
      "140/140 [==============================] - 91s 649ms/step - loss: 0.9133 - out_class_loss: 1.2030 - out_asymm_loss: 0.6235 - out_class_acc: 0.1850 - val_loss: 0.4886 - val_out_class_loss: 0.7330 - val_out_asymm_loss: 0.2441 - val_out_class_acc: 0.2029\n",
      "Epoch 23/200\n",
      "140/140 [==============================] - 91s 649ms/step - loss: 0.9042 - out_class_loss: 1.1961 - out_asymm_loss: 0.6124 - out_class_acc: 0.1821 - val_loss: 0.5147 - val_out_class_loss: 0.7296 - val_out_asymm_loss: 0.2998 - val_out_class_acc: 0.1914\n",
      "Epoch 24/200\n",
      "140/140 [==============================] - 91s 649ms/step - loss: 0.9175 - out_class_loss: 1.2064 - out_asymm_loss: 0.6286 - out_class_acc: 0.1864 - val_loss: 0.4907 - val_out_class_loss: 0.7322 - val_out_asymm_loss: 0.2491 - val_out_class_acc: 0.1914\n",
      "Epoch 25/200\n",
      "140/140 [==============================] - 91s 649ms/step - loss: 0.9063 - out_class_loss: 1.1997 - out_asymm_loss: 0.6128 - out_class_acc: 0.1836 - val_loss: 0.4753 - val_out_class_loss: 0.7300 - val_out_asymm_loss: 0.2206 - val_out_class_acc: 0.1914\n",
      "Epoch 26/200\n",
      "116/140 [=======================>......] - ETA: 14s - loss: 0.8863 - out_class_loss: 1.1743 - out_asymm_loss: 0.5983 - out_class_acc: 0.1733"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 91s 650ms/step - loss: 0.9115 - out_class_loss: 1.2046 - out_asymm_loss: 0.6183 - out_class_acc: 0.1857 - val_loss: 0.4825 - val_out_class_loss: 0.7371 - val_out_asymm_loss: 0.2278 - val_out_class_acc: 0.1914\n",
      "Epoch 33/200\n",
      "118/140 [========================>.....] - ETA: 13s - loss: 0.9075 - out_class_loss: 1.2085 - out_asymm_loss: 0.6066 - out_class_acc: 0.1873"
     ]
    }
   ],
   "source": [
    "tfdir = cf.DATA_CONFIG['project_folder'] + 'logs/multitask/'\n",
    "bs=10\n",
    "tensorboard = TensorBoard(log_dir=tfdir, write_graph=True)\n",
    "callbacks = [tensorboard]\n",
    "\n",
    "#Compile model\n",
    "opt=keras.optimizers.SGD(lr=0.001, momentum=0.90)\n",
    "model.compile(loss={'out_class': 'binary_crossentropy', 'out_asymm':'mse'}, optimizer=opt, metrics={'out_class': 'accuracy'}, loss_weights={'out_class': 0.5, 'out_asymm': 0.5})\n",
    "\n",
    "#Fit model\n",
    "history=model.fit_generator(train, steps_per_epoch=(len(train_id)//bs), epochs=200,  class_weight={'out_class':{0:1.,1:5.}}, validation_data=validation, validation_steps=(len(valid_id)//bs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(cf.DATA_CONFIG['project_folder'] + \"weights/mu.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(cf.DATA_CONFIG['project_folder'] + \"weights/mu.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "\tmask=[]\n",
    "\tfor i in range(0,10):\n",
    "\t\tif y_true[i]==0\t:\n",
    "\t\t\tmask.append(0.0)\n",
    "\t\telse: \n",
    "\t\t\tmask.append(1.0)\n",
    "\tif all(value == 0 for value in mask):\n",
    "\t\t\n",
    "\t\treturn 0.\n",
    "\telse:\n",
    "\t\tmask=np.array(mask)\n",
    "\t\tmask = K.cast(mask, K.floatx())\n",
    "\t\tscore_array = K.square(y_true- y_pred)\n",
    "\t\tscore_array *= mask\n",
    "\t\tscore_array /= K.mean(K.cast(K.not_equal(mask, 0), K.floatx()))\n",
    "\t\treturn K.mean(score_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make prediction\n",
    "y_pred = load_model.predict_generator(test, steps=25)\n",
    "y_pred_c=(y_pred[0])\n",
    "y_true_c=test_label_c\n",
    "y_pred_c=np.array(y_pred_c)\n",
    "\n",
    "\n",
    "#Confusion matrix\n",
    "classes={'nevus': 0, 'melanoma': 1}\n",
    "thre=0.5\n",
    "# obtain class predictions from probabilities\n",
    "y_predi=(y_pred_c>=thre)*1\n",
    "# obtain (unnormalized) confusion matrix\n",
    "cm = confusion_matrix(y_true_c, y_predi)\n",
    "# normalize confusion matrix\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "   \n",
    "plt.figure()\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "thresh = cm.max() / 2.\n",
    "\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "\tplt.text(j, i, format(cm[i, j], '.2f'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.savefig(cf.DATA_CONFIG['project_folder'] + 'reports/Multitask_Confusion_Matrix.png')\n",
    "plt.show()\n",
    "\n",
    "#ROC curve and score\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "fpr, tpr, _ = roc_curve(y_true_c, y_pred_c)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "label='ROC curve  (area = {f:.2f})'.format( f=roc_auc))\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.savefig(cf.DATA_CONFIG['project_folder'] + 'Multitask_ROC.png')\n",
    "plt.show()\n",
    "\n",
    "#Calcuate correlation coefficient\n",
    "y_pred_a=y_pred[1].reshape((250,))\n",
    "y_true_a=np.array(test_label_a)\n",
    "\n",
    "#Remove all zeros from missing labels\n",
    "for index in range(0,250):\n",
    "\tif y_true_a[index]==0:\n",
    "\t\ty_pred_a[index]=0\n",
    "\n",
    "y_pred_a = y_pred_a[y_pred_a != 0]\n",
    "y_true_a = y_true_a[y_true_a != 0]\n",
    "\n",
    "r, p = stats.pearsonr(y_true_a, y_pred_a)\n",
    "alpha=0.05\n",
    "r_z = np.arctanh(r)\n",
    "se = 1/np.sqrt(y_true_a.size-3)\n",
    "z = stats.norm.ppf(1-alpha/2)\n",
    "lo_z, hi_z = r_z-z*se, r_z+z*se\n",
    "lo, hi = np.tanh((lo_z, hi_z))\n",
    "corr_coef=np.corrcoef(y_pred_a, y_true_a)\n",
    "\n",
    "#Plot correlation scatter plot\n",
    "y_p_1=[]\n",
    "y_t_1=[]\n",
    "y_p_2=[]\n",
    "y_t_2=[]\n",
    "for i in range(len(y_true_a)):\n",
    "\tif test_label_c[i]==1:\n",
    "\t\ty_p_1.append(y_pred_a[i])\n",
    "\t\ty_t_1.append(y_true_a[i])\n",
    "\telse:\n",
    "\t\ty_p_2.append(y_pred_a[i])\n",
    "\t\ty_t_2.append(y_true_a[i])\n",
    "y_p_1=np.array(y_p_1)\n",
    "y_t_1=np.array(y_t_1)\n",
    "y_p_2=np.array(y_p_2)\n",
    "y_t_2=np.array(y_t_2)\n",
    "plt.scatter(y_t_1, y_p_1, color='r')\t#red points for melanoma\n",
    "plt.scatter(y_t_2, y_p_2, color='b')\t#blue points for non-melanoma\n",
    "plt.xlabel(\"G_truth\")\n",
    "plt.ylabel(\"predicted\")\n",
    "plt.figtext(0.01, 0.95, 'corr_coef='+str(r), fontsize=10)\n",
    "plt.figtext(0.01, 0.92, 'hi='+str(hi), fontsize=10)\n",
    "plt.figtext(0.01, 0.89, 'lo='+str(lo), fontsize=10)\n",
    "plt.show()\n",
    "plt.savefig(cf.DATA_CONFIG['project_folder'] + 'Correlation_Scatter_Plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
